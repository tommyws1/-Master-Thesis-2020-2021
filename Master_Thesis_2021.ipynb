{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Master Thesis 2021.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttBmv392QmfM",
        "outputId": "0dbd34ec-4830-4c75-e725-9a0635e88224"
      },
      "source": [
        "##importing the file of the combined transcripts and labels of alfano the students and raf etc.\n",
        "import csv\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "csv.field_size_limit(1000000)\n",
        "\n",
        "combined = []\n",
        "      \n",
        "with open('combined3.csv', 'r',newline='', encoding='utf8') as f:\n",
        "  csv_reader = csv.reader(f, delimiter=',')\n",
        "  for i, row in enumerate(csv_reader):\n",
        "    if i == 0:\n",
        "      continue\n",
        "    else:\n",
        "      combined.append(row)\n",
        "\n",
        "print(combined[0][1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G33i9P2ZQmfR"
      },
      "source": [
        "##splitting the data into test and training set\n",
        "def dat_shuffle(combined):  \n",
        "    X = []\n",
        "    y = []                 \n",
        "    for item in combined:\n",
        "        if item[1] != 'x':\n",
        "            X.append(item[0])\n",
        "        if item[1] != 'x':\n",
        "            if(int(item[1])==2 or int(item[1])==3):\n",
        "               val = 0\n",
        "            else:\n",
        "               val = 1\n",
        "            y.append(int(val))\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    from sklearn.model_selection import StratifiedShuffleSplit\n",
        "    indiced = StratifiedShuffleSplit(n_splits=20, test_size=0.2, random_state=4)\n",
        "\n",
        "    for train_index, test_index in indiced.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "    training_data = []\n",
        "\n",
        "\n",
        "    test_data = []\n",
        "\n",
        "    for i, item in enumerate(X_train):\n",
        "        training_data.append([str(X_train[i]), y_train[i]])\n",
        "    for i, item in enumerate(X_test):\n",
        "        test_data.append([str(X_test[i]), y_test[i]])\n",
        "    \n",
        "\n",
        "\n",
        "    return test_data, training_data, X_train, X_test,  y_train, y_test     "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N84JdbdUQmfS",
        "outputId": "310de54b-516d-4679-c0b6-b26beb69797f"
      },
      "source": [
        "test_data, training_data, X_train, X_test,  y_train, y_test = dat_shuffle(combined)\n",
        "test_data[1]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"[Applause] [Music]  what's up guys this is the honest out lot here and today we're gonna be doing a pretty funny video we're gonna be talking about seven guns that I wish I didn't buy now I'm gonna get some hate from the fanboys from this video and I understand why I'm not saying all these guns will be terrible for you I'm just saying for one reason or another they were terrible for me and I wish it didn't buy them in this list I'm gonna try to explain why I bought them originally why I hated them and some options that I would recommend buying instead so let's get started at number 7 my Wilson combat in 1911 now I got to admit I've wanted a wolfson combat for as long as I can remember all I've heard were awesome things about it the most reliable the most accurate 1911 on the planet with top-notch craftsmanship and a slide is smooth is a baby seals ass looks like a super model and it handles like a dream almost all of that is actually true believe it or not except for the reliability which I wish I could say it didn't have issues with but I feel like I had many more reliability issues than I should have for the whopping four thousand dollar price tag but the real problem that I had afterward was the resale value if you decide to sell your gun after you get it you'll be lucky to get right around three quarters what you paid for it and if you're bad at math that's about a thousand dollar loss minimum I really can't stress enough how disappointed I was especially considering my Springfield and Dan Wesson 1911 s performed better and costs a lot less money number six is going to be the kel-tec pf9 now I'm not a Celtic hater by far but let's be honest there's a few good designs that they have but there's also a lot that you should stay away from and this for me is one of those for sure I bought it because it was very light weight one of the lightest nine-millimeter pistols on the market at right around 12 ounces which is pretty impressive and it's also really cheap I think I got it at a gun show for right around $200 and lastly it comes highly recommended by one of the youtubers I like nothing fancy so how bad could it be right think about it for a second put a nine-millimeter round in an unreliable 12 ounce frame with no traction to speak up and what do you get for me you get a fairly unsuitable gun yes it's lightweight and a reasonable caliber but if you can't hit anything what's the point the recoil was extreme enough that my why didn't even want to practice with it and if you don't practice so that you might as well not carry it because you won't be able to shoot it effectively it did have some pretty serious reliability issues in a lot of the ammo that I tried and for me if I buy a 9-millimeter pistol there's so many options on the market today if it doesn't shoot everything 9-millimeter I get tired of it pretty quick and move on to something that does if you're gonna buy a subcompact single stack for me I would stick with a reputable company like Glock Smith & Wesson or Walther number five the Taurus 608 now tourist doesn't get a lot of love for me and I think that's for good reason I bought this gun because of the price $600 compared to a thousand for the Smith & Wesson since it's on the list of guns I regret buying you can guess I should have just went with the Smith & Wesson I also got this revolver because it was eight shots of 357 very impressive it came with a ported barrel and high-vis adjustable sights that's a lot of great features for the money however in classic Taurus fashion they sacrificed build quality and reliability for cool factor in features this gun could barely get through a full cylinder without a failure if I were you I would pick up a Ruger or Smith & Wesson buy once cry once at number four the car CW 380 another unreliable pocket pistol makes the list the car is great on paper coming in at a featherweight ten ounces making it one of the lightest pistols you can carry with a reasonable caliber for self-defense it also comes with the car name which has a great track record but this gun could barely get through a magazine of any animal that I fed it not to mention the terrible trigger by today's standards I know a lot of you like it but you should try a ppq and get back to me also I happen to be pretty tall so this tiny gun barely fit in my hands to begin with it might be great for your grandma but it's not great for me and I'm glad I sold it if you're in the market for a 380 pocket pistol check out the Ruger LCP Glock 42 or the very very awesome sig p228 number three the remington rp9 now normally I give guns the benefit of the doubt but this gun is just a huge piece of crap add it to the list of failed remington products in the last 10 years thanks freedom group way to ruin one of the oldest firearm companies in the world this may be the least reliable gunner this year not to mention the grip was absolutely terrible maybe the worst that I've tried there was no texture at all and it literally felt like a broomstick a very spongy trigger that worked about 75% of the time with no tactile or audible reset not to mention the fact that it slaps you in the finger every time you shoot it so how did Remington decide to turn this sinking ship around well they decided to hire the old CEO of Taurus I wouldn't hold your breath thinking that Remington's quality will increase anytime soon with so many alternatives to this gun why even buy it get yourself a Glock ppq Sig XD cz Smith & Wesson or almost anything else at number two the DPMS g2 recon this is the gun that started my channel I was very excited for this gun to be released and I bought it soon after on the recommendation of reputable people on YouTube like James Yeager it was supposed to be as light as an ar-15 very reliable very accurate and you could even take some standard ar-15 parts and put them on this 308 gun what I got however was a little bit different than advertised the gun that I purchased wouldn't function a single round right out of the box and it had to be sent back to have the bolt resized so it would at least move back and forth inside the rifle I got it back a couple of months later it's still malfunctioned one or two times every hundred rounds or so however I did fix that issue as well myself by adding an adjustable gas block it also was not as accurate as advertised to say the least about one to one and a half M away at best I have record air fifteens that shoot better than that did I mention that it recoiled like a truck full of dildos falling off a bridge and landing on your shoulder I might be exaggerating a little bit here but it still had about double the recoil of my M and P 10 and they're the exact same type of gun shooting the exact same caliber I decided after this gun that I would start a youtube channel and I would be honest about my experiences so people don't have to go through what I went through to find out what gun works the best for them for me personally if you're looking for g2 recon I would steer more towards arrow precision or definitely the Smith & Wesson M&P and number one it takes a lot to get to number one on this list but you made it the ultra 87 by Century Arms this is an 870 clone in 12-gauge I did a video on this gun titled the worst gun ever and pretty much everyone who saw agreed it's a cheap Chinese copy of an 870 imported by Century Arms why did I buy it you asked bought it because I've always bought brand-name shotguns like mosburger Remington and I wanted to try something different not to mention this gun was a little bit under $200 to add insult to injury my buddy needed a shotgun and I hadn't tried this out yet he was on a very strict budget so I gave it to him he shot about a box of ammo through it before the rails inside the receiver that the bolt rides on completely sheared off they're made of metal about as tough as a melted beer can so I guess I wasn't that surprised the bullet got jammed inside the receiver so hard that it wouldn't work and you couldn't break the action down to see what was wrong after taking it to a gunsmith to find out that my new gun no longer works and it would cost me more to fix it than buy a new shotgun of higher quality I decided to make the video and I stand by it please do yourself a favor and spend the extra fifty to a hundred dollars and at least get a Mossberg maverick use 500 or even a use 870 all three will last you your entire life and you'll be able to hand them down to your children and your entire life is a little bit longer than a box of birdshot if you liked this video please like and subscribe I usually leave a link to a local homeless shelter in the description you can go down there and click the link and I'll bring you right to the donate page and you can donate to this youth homeless shelter that could really use your support if you have a little bit of money after that you could always hit up my patreon account it's also in the description below the shelter I could use your support as well considering YouTube is not quite as friendly to gun related content as it used to be please sell out your local homeless shelters and remember to recycle I'll check you later I didn't load it  [Music]\",\n",
              " 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIhkuS5aQmfT"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.models import Model, Input, Sequential\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, SpatialDropout1D, Activation\n",
        "from keras.layers import Conv1D, Bidirectional, GlobalMaxPool1D, MaxPooling1D, BatchNormalization\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB0FTAp_QmfU",
        "outputId": "a6391658-6580-47d1-8432-16f3f79896bb"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=20000)\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "\n",
        "# turning the tokenized text into sequences\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test  = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# padding the sequences\n",
        "X_train = sequence.pad_sequences(X_train,maxlen= 10000)\n",
        "X_test  = sequence.pad_sequences(X_test,maxlen=10000)\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape: ', X_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (385, 10000)\n",
            "X_test shape:  (97, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yrb1zX3QmfV",
        "outputId": "30f70980-7e10-4abf-9465-2cc04cdea9e9"
      },
      "source": [
        "X_train[1]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0, ..., 318, 318, 137], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtBp48XXQmfX"
      },
      "source": [
        "# number of unique words we want to use (or: number of rows in incoming embedding vector)\n",
        "max_features = 20000 \n",
        "\n",
        "# max number of words in a comment to use (or: number of columns in incoming embedding vector)\n",
        "max_len = 10000 \n",
        "\n",
        "# dimension of the embedding variable (or: number of rows in output of embedding vector)\n",
        "embedding_dims = 128"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWIdDWgvQmfY"
      },
      "source": [
        "# instantiate NN model\n",
        "base_model = Sequential()\n",
        "\n",
        "# add embedding layer \n",
        "base_model.add(Embedding(input_dim=max_features, input_length=max_len,\n",
        "                         output_dim=embedding_dims))\n",
        "\n",
        "# add pooling layer \n",
        "# ... which will extract features from the embeddings of all words in the comment\n",
        "base_model.add(GlobalMaxPool1D())\n",
        "\n",
        "# add dense layer to produce an output dimension of 50 and apply relu activation\n",
        "base_model.add(Dense(50, activation='relu'))\n",
        "\n",
        "# set the regularizing dropout layer to drop out 30% of the nodes\n",
        "base_model.add(Dropout(0.3))\n",
        "\n",
        "# finally add a dense layer\n",
        "# ... which projects output into six units and squash it with sigmoid activation\n",
        "base_model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4RfC_6IQmfZ",
        "outputId": "718e9dc9-726e-4fe7-cce6-a2f6ec3706bb"
      },
      "source": [
        "base_model.compile(loss='binary_crossentropy',\n",
        "                   optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "# check the model with all our layers\n",
        "base_model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 10000, 128)        2560000   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                6450      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 2,566,501\n",
            "Trainable params: 2,566,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv9fZgirQmfZ",
        "outputId": "703493d7-1901-4c49-9196-b036c1ea533b"
      },
      "source": [
        "##Gives an error in anaconda but works in google colab \n",
        "base_hist = base_model.fit(X_train, y_train, batch_size=64, \n",
        "                             epochs=15, validation_split=0.1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 0.6041 - accuracy: 0.7168 - val_loss: 0.5769 - val_accuracy: 0.7436\n",
            "Epoch 2/15\n",
            "6/6 [==============================] - 3s 492ms/step - loss: 0.5923 - accuracy: 0.7168 - val_loss: 0.5745 - val_accuracy: 0.7436\n",
            "Epoch 3/15\n",
            "6/6 [==============================] - 3s 488ms/step - loss: 0.5926 - accuracy: 0.7168 - val_loss: 0.5733 - val_accuracy: 0.7436\n",
            "Epoch 4/15\n",
            "6/6 [==============================] - 3s 486ms/step - loss: 0.5948 - accuracy: 0.7168 - val_loss: 0.5729 - val_accuracy: 0.7436\n",
            "Epoch 5/15\n",
            "6/6 [==============================] - 3s 483ms/step - loss: 0.5873 - accuracy: 0.7168 - val_loss: 0.5727 - val_accuracy: 0.7436\n",
            "Epoch 6/15\n",
            "6/6 [==============================] - 3s 490ms/step - loss: 0.5876 - accuracy: 0.7168 - val_loss: 0.5726 - val_accuracy: 0.7436\n",
            "Epoch 7/15\n",
            "6/6 [==============================] - 3s 489ms/step - loss: 0.5775 - accuracy: 0.7168 - val_loss: 0.5716 - val_accuracy: 0.7436\n",
            "Epoch 8/15\n",
            "6/6 [==============================] - 3s 490ms/step - loss: 0.5749 - accuracy: 0.7168 - val_loss: 0.5704 - val_accuracy: 0.7436\n",
            "Epoch 9/15\n",
            "6/6 [==============================] - 3s 489ms/step - loss: 0.5734 - accuracy: 0.7168 - val_loss: 0.5696 - val_accuracy: 0.7436\n",
            "Epoch 10/15\n",
            "6/6 [==============================] - 3s 489ms/step - loss: 0.5656 - accuracy: 0.7168 - val_loss: 0.5679 - val_accuracy: 0.7436\n",
            "Epoch 11/15\n",
            "6/6 [==============================] - 3s 486ms/step - loss: 0.5568 - accuracy: 0.7168 - val_loss: 0.5647 - val_accuracy: 0.7436\n",
            "Epoch 12/15\n",
            "6/6 [==============================] - 3s 484ms/step - loss: 0.5444 - accuracy: 0.7168 - val_loss: 0.5603 - val_accuracy: 0.7436\n",
            "Epoch 13/15\n",
            "6/6 [==============================] - 3s 488ms/step - loss: 0.5247 - accuracy: 0.7168 - val_loss: 0.5548 - val_accuracy: 0.7436\n",
            "Epoch 14/15\n",
            "6/6 [==============================] - 3s 487ms/step - loss: 0.5165 - accuracy: 0.7168 - val_loss: 0.5470 - val_accuracy: 0.7436\n",
            "Epoch 15/15\n",
            "6/6 [==============================] - 3s 486ms/step - loss: 0.4986 - accuracy: 0.7168 - val_loss: 0.5375 - val_accuracy: 0.7436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4Q76vevvaxX",
        "outputId": "4476e186-b218-4db3-87e6-b8cf64d1ec7b"
      },
      "source": [
        "base_test_loss, base_test_auc = base_model.evaluate(X_test, y_test, batch_size=32)\r\n",
        "print('Test Loss:    ', base_test_loss)\r\n",
        "print('Test Accuracy:', base_test_auc)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 50ms/step - loss: 0.5527 - accuracy: 0.7216\n",
            "Test Loss:     0.5527227520942688\n",
            "Test Accuracy: 0.7216494679450989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DasdD2hQmfa",
        "outputId": "ba52113e-3f23-4916-afe5-39d570338652"
      },
      "source": [
        "## importing  pretrained glove\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "# first, build index mapping words in the embeddings set\n",
        "# to their embedding vector\n",
        "\n",
        "print('Indexing word vectors.')\n",
        "\n",
        "embeddings_index = {}\n",
        "with open( 'glove.6B.100d.txt',encoding=\"utf8\") as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indexing word vectors.\n",
            "Found 347217 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNECiodaQmfb"
      },
      "source": [
        "# constructing a matrix for the glove vectors\n",
        "embedding_matrix = np.zeros((len(tokenizer.word_index)+1, 100))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiFRzk70Qmfb",
        "outputId": "1f53fb2e-2ea1-4524-c9df-0300a644f323"
      },
      "source": [
        "##implementing CNN with pretrained glove\n",
        "glove_model = Sequential()\n",
        "\n",
        "# add embedding layer \n",
        "glove_model.add(Embedding(input_dim =embedding_matrix.shape[0], input_length=10000,\n",
        "                          output_dim=embedding_matrix.shape[1], \n",
        "                          weights=[embedding_matrix], trainable=False))\n",
        " \n",
        "# set the dropout layer to drop out 50% of the nodes\n",
        "glove_model.add(SpatialDropout1D(0.5))\n",
        "\n",
        "# add convolutional layer that has ...\n",
        "# ... 100 filters with a kernel size of 4 so that each convolution will consider a window of 4 word embeddings\n",
        "glove_model.add(Conv1D(filters=100, kernel_size=4, padding='same', activation='relu'))\n",
        "# add normalization layer\n",
        "glove_model.add(BatchNormalization())\n",
        "# add pooling layer \n",
        "glove_model.add(GlobalMaxPool1D())\n",
        "\n",
        "# set the dropout layer to drop out 50% of the nodes\n",
        "glove_model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "# add dense layer to produce an output dimension of 50 and using relu activation\n",
        "glove_model.add(Dense(50, activation='relu'))\n",
        "\n",
        "# finally add a dense layer\n",
        "glove_model.add(Dense(1, activation='sigmoid'))\n",
        "glove_model.compile(loss='binary_crossentropy',\n",
        "                    optimizer=\"adam\",\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "glove_model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 10000, 100)        3524100   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_5 (Spatial (None, 10000, 100)        0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 10000, 100)        40100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 10000, 100)        400       \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_6 (Glob (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 3,569,701\n",
            "Trainable params: 45,401\n",
            "Non-trainable params: 3,524,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O86ROC2sQmfc",
        "outputId": "c47f33f1-90eb-4d13-d39f-9846ac8a4e23"
      },
      "source": [
        "glove_hist = glove_model.fit(X_train, y_train, batch_size=64, \n",
        "                             epochs=15, validation_split=0.1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "6/6 [==============================] - 19s 3s/step - loss: 5.2950 - accuracy: 0.4627 - val_loss: 0.9229 - val_accuracy: 0.2564\n",
            "Epoch 2/15\n",
            "6/6 [==============================] - 18s 3s/step - loss: 3.2799 - accuracy: 0.6678 - val_loss: 1.0325 - val_accuracy: 0.2564\n",
            "Epoch 3/15\n",
            "6/6 [==============================] - 18s 3s/step - loss: 2.0242 - accuracy: 0.6408 - val_loss: 0.9409 - val_accuracy: 0.2564\n",
            "Epoch 4/15\n",
            "6/6 [==============================] - 18s 3s/step - loss: 1.7468 - accuracy: 0.6099 - val_loss: 0.7536 - val_accuracy: 0.3333\n",
            "Epoch 5/15\n",
            "6/6 [==============================] - 18s 3s/step - loss: 1.8936 - accuracy: 0.6389 - val_loss: 0.7666 - val_accuracy: 0.2821\n",
            "Epoch 6/15\n",
            "6/6 [==============================] - 18s 3s/step - loss: 1.6965 - accuracy: 0.5851 - val_loss: 0.7543 - val_accuracy: 0.3333\n",
            "Epoch 7/15\n",
            "6/6 [==============================] - 18s 3s/step - loss: 1.3292 - accuracy: 0.6404 - val_loss: 0.6909 - val_accuracy: 0.5128\n",
            "Epoch 8/15\n",
            "6/6 [==============================] - 18s 3s/step - loss: 1.4247 - accuracy: 0.6047 - val_loss: 0.6297 - val_accuracy: 0.7436\n",
            "Epoch 9/15\n",
            "6/6 [==============================] - 18s 3s/step - loss: 1.2376 - accuracy: 0.6159 - val_loss: 0.6306 - val_accuracy: 0.7692\n",
            "Epoch 10/15\n",
            "6/6 [==============================] - 18s 3s/step - loss: 1.5275 - accuracy: 0.5625 - val_loss: 0.6257 - val_accuracy: 0.7692\n",
            "Epoch 11/15\n",
            "6/6 [==============================] - 18s 3s/step - loss: 1.1310 - accuracy: 0.6422 - val_loss: 0.6382 - val_accuracy: 0.7949\n",
            "Epoch 12/15\n",
            "6/6 [==============================] - 18s 3s/step - loss: 1.3022 - accuracy: 0.5784 - val_loss: 0.6358 - val_accuracy: 0.6923\n",
            "Epoch 13/15\n",
            "6/6 [==============================] - 18s 3s/step - loss: 1.1340 - accuracy: 0.6292 - val_loss: 0.6388 - val_accuracy: 0.7436\n",
            "Epoch 14/15\n",
            "6/6 [==============================] - 18s 3s/step - loss: 1.0654 - accuracy: 0.6066 - val_loss: 0.6222 - val_accuracy: 0.7949\n",
            "Epoch 15/15\n",
            "6/6 [==============================] - 18s 3s/step - loss: 1.0046 - accuracy: 0.6450 - val_loss: 0.6211 - val_accuracy: 0.7692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAAKULRmQmfd",
        "outputId": "edb808d3-b73a-457a-8d68-47c7e5b2c4f8"
      },
      "source": [
        "## testing trained model on the test set\n",
        "glove_test_loss, glove_test_auc = glove_model.evaluate(X_test, y_test, batch_size=64)\n",
        "print('Test Loss:    ', glove_test_loss)\n",
        "print('Test Accuracy:', glove_test_auc)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 427ms/step - loss: 0.5898 - accuracy: 0.8454\n",
            "Test Loss:     0.5898271799087524\n",
            "Test Accuracy: 0.8453608155250549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eke-tZZDQmfe"
      },
      "source": [
        "##desinging a RNN\n",
        "# instantiate pretrained glove model\n",
        "glove_2_model = Sequential()\n",
        "\n",
        "# add embedding layer \n",
        "glove_2_model.add(Embedding(input_dim =embedding_matrix.shape[0], input_length=10000,\n",
        "                          output_dim=embedding_matrix.shape[1], \n",
        "                          weights=[embedding_matrix], trainable=False))\n",
        "\n",
        "# set the dropout layer to drop out 50% of the nodes\n",
        "glove_2_model.add(SpatialDropout1D(0.5))\n",
        "\n",
        "# add bidirectional layer and pass in an LSTM()\n",
        "glove_2_model.add(Bidirectional(LSTM(25, return_sequences=True)))\n",
        "\n",
        "# add normalization layer\n",
        "glove_2_model.add(BatchNormalization())\n",
        "\n",
        "# add pooling layer \n",
        "glove_2_model.add(GlobalMaxPool1D())\n",
        "\n",
        "# set the dropout layer to drop out 50% of the nodes\n",
        "glove_2_model.add(Dropout(0.5))\n",
        "\n",
        "# add dense layer to produce an output dimension of 50 and using relu activation\n",
        "glove_2_model.add(Dense(50, activation='relu'))\n",
        "\n",
        "# finally add a dense layer\n",
        "glove_2_model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avCRwPx2Qmfe",
        "outputId": "93d23543-8cb1-45e7-e013-7f16a5d42fe5"
      },
      "source": [
        "glove_2_model.compile(loss='binary_crossentropy',\n",
        "                    optimizer=\"adam\",\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "glove_2_model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 10000, 100)        3524100   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 10000, 100)        0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 10000, 50)         25200     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 10000, 50)         200       \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 3,552,101\n",
            "Trainable params: 27,901\n",
            "Non-trainable params: 3,524,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnvHozFHQmff",
        "outputId": "8572a759-19c5-44cf-9807-69ffd5b48971"
      },
      "source": [
        "glove_2_hist = glove_2_model.fit(X_train, y_train, batch_size=64, \n",
        "                                 epochs=20, validation_split=0.1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 71s 11s/step - loss: 0.6230 - accuracy: 0.7044 - val_loss: 0.5563 - val_accuracy: 0.7692\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 68s 11s/step - loss: 0.5914 - accuracy: 0.7001 - val_loss: 0.5507 - val_accuracy: 0.7692\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 68s 11s/step - loss: 0.5850 - accuracy: 0.7338 - val_loss: 0.5462 - val_accuracy: 0.7692\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 68s 11s/step - loss: 0.5709 - accuracy: 0.7419 - val_loss: 0.5439 - val_accuracy: 0.7692\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 67s 11s/step - loss: 0.5752 - accuracy: 0.7278 - val_loss: 0.5427 - val_accuracy: 0.7692\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 70s 12s/step - loss: 0.5864 - accuracy: 0.7253 - val_loss: 0.5418 - val_accuracy: 0.7949\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 68s 11s/step - loss: 0.5927 - accuracy: 0.7204 - val_loss: 0.5384 - val_accuracy: 0.7949\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 68s 11s/step - loss: 0.5718 - accuracy: 0.7563 - val_loss: 0.5341 - val_accuracy: 0.7949\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 68s 11s/step - loss: 0.5928 - accuracy: 0.7367 - val_loss: 0.5321 - val_accuracy: 0.7949\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 68s 11s/step - loss: 0.6088 - accuracy: 0.7205 - val_loss: 0.5317 - val_accuracy: 0.7949\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 69s 11s/step - loss: 0.5828 - accuracy: 0.7296 - val_loss: 0.5305 - val_accuracy: 0.7949\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 68s 11s/step - loss: 0.5865 - accuracy: 0.7406 - val_loss: 0.5310 - val_accuracy: 0.7949\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 68s 11s/step - loss: 0.5875 - accuracy: 0.7543 - val_loss: 0.5310 - val_accuracy: 0.7949\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 69s 12s/step - loss: 0.5908 - accuracy: 0.7288 - val_loss: 0.5290 - val_accuracy: 0.7949\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 68s 11s/step - loss: 0.5951 - accuracy: 0.7026 - val_loss: 0.5266 - val_accuracy: 0.7949\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 68s 11s/step - loss: 0.5871 - accuracy: 0.7305 - val_loss: 0.5230 - val_accuracy: 0.7949\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 68s 11s/step - loss: 0.5744 - accuracy: 0.7293 - val_loss: 0.5234 - val_accuracy: 0.7949\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 68s 11s/step - loss: 0.5820 - accuracy: 0.7328 - val_loss: 0.5247 - val_accuracy: 0.7949\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 69s 12s/step - loss: 0.5995 - accuracy: 0.7415 - val_loss: 0.5252 - val_accuracy: 0.7949\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 69s 12s/step - loss: 0.5799 - accuracy: 0.7519 - val_loss: 0.5228 - val_accuracy: 0.7949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oZW9ORSQmfg",
        "outputId": "d992f641-a98e-426b-c5f6-879b535ffd59"
      },
      "source": [
        "glove_2_test_loss, glove_2_test_auc = glove_2_model.evaluate(X_test, y_test, batch_size=32)\n",
        "print('Test Loss:    ', glove_2_test_loss)\n",
        "print('Test Accuracy:', glove_2_test_auc)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 970ms/step - loss: 0.5383 - accuracy: 0.7938\n",
            "Test Loss:     0.5382745265960693\n",
            "Test Accuracy: 0.7938144207000732\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}